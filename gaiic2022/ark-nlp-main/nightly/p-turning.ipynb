{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cba3d0-eae6-4350-955b-541c736c0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9f5bd-ac77-41fb-804a-1df52dec4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目录地址\n",
    "train_data_path = '../data/source_datasets/tnews/train_few_all.json'\n",
    "dev_data_path = '../data/source_datasets/tnews/test_public.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a133533-cacf-4f29-bbd8-01b117f4ac0d",
   "metadata": {},
   "source": [
    "### 一、数据读入与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44393d-67ac-4402-874d-5e8c6481cb0a",
   "metadata": {},
   "source": [
    "#### 1. 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc82cd-b6e7-46d5-bc32-cf645a38e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_en2zh = {'news_tech': '科技', 'news_entertainment': '娱乐', 'news_car': '汽车', 'news_travel': '旅游',\n",
    "               'news_finance': '财经',\n",
    "               'news_edu': '教育', 'news_world': '国际', 'news_house': '房产', 'news_game': '电竞', 'news_military': '军事',\n",
    "               'news_story': '故事', 'news_culture': '文化', 'news_sports': '体育', 'news_agriculture': '农业',\n",
    "               'news_stock': '股票'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5727678-2f74-49ee-b511-9bca8b78e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):  # 加载数据\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            l = json.loads(l)\n",
    "            l['label_zh'] = label_en2zh[l['label_desc']]\n",
    "            D.append(l)\n",
    "    df = pd.DataFrame(D)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data_df = load_data(train_data_path)\n",
    "train_data_df = (train_data_df\n",
    "                     .loc[:, ['sentence', 'label_zh']]).rename(columns={'sentence': 'text', 'label_zh': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895f4ad-afda-4b18-b589-d320c95e4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_df = load_data(dev_data_path)\n",
    "dev_data_df = (dev_data_df\n",
    "                     .loc[:, ['sentence', 'label_zh']]).rename(columns={'sentence': 'text', 'label_zh': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c9876-235c-452f-ba4d-0e4ad3c42b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark_nlp.dataset import SentenceClassificationDataset\n",
    "\n",
    "\n",
    "class PTurningDataset(SentenceClassificationDataset):\n",
    "    \"\"\"\n",
    "    将单句分类任务转换为MLM任务\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        *args, \n",
    "        prompt=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(PTurningDataset, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        if self.is_test and mask_lm_label_size is None:\n",
    "            raise ValueError(\"The mask_lm_label_size must not be None\")\n",
    "                    \n",
    "        if prompt is not None:\n",
    "            self.prompt = prompt\n",
    "            self.mask_lm_label_size = self.prompt.count(\"[MASK]\") \n",
    "\n",
    "\n",
    "    def _convert_to_transfomer_ids(self, bert_tokenizer):\n",
    "\n",
    "        features = []\n",
    "        \n",
    "        start_mask_position = self.prompt.index(\"[MASK]\")\n",
    "        \n",
    "        mask_position = [\n",
    "            start_mask_position + index\n",
    "            for index in range(self.mask_lm_label_size)\n",
    "        ]\n",
    "        \n",
    "        for (index_, row_) in enumerate(self.dataset):\n",
    "            \n",
    "            input_ids = bert_tokenizer.sequence_to_ids(row_['text'], self.prompt)\n",
    "            \n",
    "            input_ids, input_mask, segment_ids = input_ids\n",
    "\n",
    "            feature = {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': input_mask,\n",
    "                'token_type_ids': segment_ids,\n",
    "                'mask_position': np.array(mask_position)\n",
    "            }\n",
    "\n",
    "            if not self.is_test:\n",
    "                label_ids = self.cat2id[row_['label']]\n",
    "                mask_lm_label = bert_tokenizer.vocab.convert_tokens_to_ids(bert_tokenizer.tokenize(row_['label']))\n",
    "                \n",
    "                feature['label_ids'] = np.array(mask_lm_label)\n",
    "\n",
    "            features.append(feature)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780193a2-8c05-4f6f-89fe-4826d232790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tokens = [\"[unused{}]\".format(i) for i in range(5)]\n",
    "mask_tokens = [\"[MASK]\"] * 2\n",
    "prompt = p_tokens + ['[CLS]'] + mask_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd3cdd-c2f4-42e0-ad39-ebb79a9af135",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_turning_train_dataset = PTurningDataset(train_data_df, prompt=prompt)\n",
    "p_turning_dev_dataset = PTurningDataset(dev_data_df, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f5e9e-54f3-44e8-a1eb-1eb1b5060c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from ark_nlp.processor.tokenizer.transfomer import TransfomerTokenizer\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "class PromptMLMTransformerTokenizer(TransfomerTokenizer):\n",
    "    \"\"\"\n",
    "    模板学习Transfomer文本编码器，用于对文本进行分词、ID化、填充等操作\n",
    "\n",
    "    Args:\n",
    "        vocab: transformers词典类对象、词典地址或词典名，用于实现文本分词和ID化\n",
    "        max_seq_len (:obj:`int`): 预设的文本最大长度\n",
    "    \"\"\"\n",
    "    def sequence_to_ids(\n",
    "        self,\n",
    "        sequence,\n",
    "        prompt,\n",
    "        return_sequence_length=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        将序列ID化\n",
    "\n",
    "        Args:\n",
    "            sequence (:obj:`str` or :obj:`list`): 输入序列\n",
    "            prompt (:obj:`list`): 模板\n",
    "            return_sequence_length (:obj:`bool`, optional, defaults to False): 返回是否包含序列长度\n",
    "        \"\"\"\n",
    "        if type(sequence) == str:\n",
    "            sequence = self.tokenize(sequence)\n",
    "\n",
    "        if return_sequence_length:\n",
    "            sequence_length = len(sequence)\n",
    "            \n",
    "        # 对超长序列进行截断\n",
    "        if len(sequence) > self.max_seq_len - 1 - len(prompt):\n",
    "            sequence = sequence[0:(self.max_seq_len - 1 - len(prompt))]\n",
    "            \n",
    "        # 分别在首尾拼接特殊符号\n",
    "        sequence = prompt + sequence + ['[SEP]']\n",
    "                \n",
    "        # ID化\n",
    "        sequence = self.vocab.convert_tokens_to_ids(sequence)\n",
    "        \n",
    "        segment_ids = [0] * len(sequence)\n",
    "        \n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (self.max_seq_len - len(sequence))\n",
    "        # 创建seq_mask\n",
    "        sequence_mask = [1] * len(sequence) + padding\n",
    "        # 创建seq_segment\n",
    "        segment_ids = segment_ids + padding\n",
    "        # 对seq拼接填充序列\n",
    "        sequence += padding\n",
    "        \n",
    "        sequence = np.asarray(sequence, dtype='int64')\n",
    "        sequence_mask = np.asarray(sequence_mask, dtype='int64')\n",
    "        segment_ids = np.asarray(segment_ids, dtype='int64')\n",
    "\n",
    "        if return_sequence_length:\n",
    "            return (sequence, sequence_mask, segment_ids, sequence_length)\n",
    "\n",
    "        return (sequence, sequence_mask, segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5250f95-9c38-4638-b0d1-ac305239d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "vocab = transformers.AutoTokenizer.from_pretrained('nghuyong/ernie-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4bb00-5b75-4845-b316-5155505887d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add_special_tokens({'additional_special_tokens': [\"[unused{}]\".format(i) for i in range(5)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d213c-f177-4c34-b901-38dfd24b8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PromptMLMTransformerTokenizer(vocab, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc52c4-6dd8-4fc2-9117-96151c1ec943",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_turning_train_dataset.convert_to_ids(tokenizer)\n",
    "p_turning_dev_dataset.convert_to_ids(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e024-2e54-4dcd-857b-a13fa50c7879",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 二、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a19c77-7b1b-4ba8-a714-8558ca21ba57",
   "metadata": {},
   "source": [
    "#### 1. 模型参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f7606-13fa-42a7-88ec-48a3968161bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\n",
    "    'nghuyong/ernie-1.0',\n",
    "    num_labels=vocab.vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efa151-58bd-4ffc-ab09-e84fde34ee58",
   "metadata": {},
   "source": [
    "#### 2. 模型创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c4208-c24d-4d80-bf06-30f5b21f1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cfdc7-c738-45b5-91ae-5ad67d66f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from transformers import BertModel\n",
    "from transformers import BertPreTrainedModel\n",
    "from transformers.models.bert.modeling_bert import BertPredictionHeadTransform\n",
    "\n",
    "from ark_nlp.nn.base.bert import Bert\n",
    "\n",
    "\n",
    "class BertLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = nn.Linear(config.hidden_size, bert_config.num_labels, bias=False)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(bert_config.num_labels))\n",
    "\n",
    "        # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "        hidden_states = self.decoder(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertForMaskedLM(Bert):\n",
    "\n",
    "    \"\"\"\n",
    "    基于BERT的mlm任务\n",
    "\n",
    "    :param config: (obejct) 模型的配置对象\n",
    "    :param bert_trained: (bool) bert参数是否可训练，默认可训练\n",
    "\n",
    "    :returns:\n",
    "\n",
    "    Reference:\n",
    "        [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            config,\n",
    "            encoder_trained=True\n",
    "    ):\n",
    "        super(BertForMaskedLM, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "\n",
    "        self.classifier = BertLMPredictionHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    @staticmethod\n",
    "    def _batch_gather(data: torch.Tensor, index: torch.Tensor):\n",
    "        \"\"\"\n",
    "        实现类似 tf.batch_gather 的效果\n",
    "        :param data: (bs, max_seq_len, hidden)\n",
    "        :param index: (bs, n)\n",
    "        :return: a tensor which shape is (bs, n, hidden)\n",
    "        \"\"\"\n",
    "        index = index.unsqueeze(-1).repeat_interleave(data.size()[-1], dim=-1)  # (bs, n, hidden)\n",
    "        return torch.gather(data, 1, index)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        mask_position=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        sequence_output = BertForMaskedLM._batch_gather(sequence_output, mask_position)\n",
    "\n",
    "        batch_size, _, hidden_size = sequence_output.shape\n",
    "        \n",
    "        sequence_output = sequence_output.reshape(-1, hidden_size)\n",
    "                \n",
    "        out = self.classifier(sequence_output)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4487fe-a5b0-44b7-8e05-31bdb38fbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_module = BertForMaskedLM.from_pretrained('nghuyong/ernie-1.0', \n",
    "                                        config=bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1bca5-5422-4ac7-a8e6-46611408be12",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 三、任务构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05cd18e-d76a-4f2c-a990-9ed5b9fdedff",
   "metadata": {},
   "source": [
    "#### 1. 任务参数和必要部件设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd75bc-a146-4eb8-9ec1-b94dc37fed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置运行次数\n",
    "num_epoches = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53298b-c749-4cac-964e-7bd245c3b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "def get_ptuning_bert_optimizer(\n",
    "    module,\n",
    "    lr: float = 3e-5,\n",
    "    eps: float = 1e-6,\n",
    "    correct_bias: bool = True,\n",
    "    weight_decay: float = 1e-3,\n",
    "):\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in module.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay},\n",
    "        {\"params\": [p for n, p in module.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=lr,\n",
    "                      eps=eps,\n",
    "                      correct_bias=correct_bias,\n",
    "                      weight_decay=weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be0754-f92c-4ebb-8ca3-462e3d0f6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_ptuning_bert_optimizer(dl_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4ff54-601f-4a9b-a564-2821fb4edbe5",
   "metadata": {},
   "source": [
    "#### 2. 任务创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39078d-6fe9-489c-89bd-46e196124501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklearn_metrics\n",
    "\n",
    "from ark_nlp.factory.task.base._sequence_classification import SequenceClassificationTask\n",
    "\n",
    "\n",
    "class PromptMLMTask(SequenceClassificationTask):\n",
    "\n",
    "    def __init__(self, *args, tokenizer=None, **kwargs):\n",
    "        super(PromptMLMTask, self).__init__(*args, **kwargs)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def _compute_loss(\n",
    "        self,\n",
    "        inputs,\n",
    "        logits,\n",
    "        verbose=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        labels = torch.squeeze(inputs['label_ids'].reshape(-1, 1))\n",
    "\n",
    "        loss = self.loss_function(logits, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _on_evaluate_begin_record(self, **kwargs):\n",
    "        self.evaluate_logs['eval_loss'] = 0\n",
    "        self.evaluate_logs['eval_acc'] = 0\n",
    "        self.evaluate_logs['eval_step'] = 0\n",
    "        self.evaluate_logs['eval_example'] = 0\n",
    "\n",
    "        self.evaluate_logs['labels'] = []\n",
    "        self.evaluate_logs['logits'] = []\n",
    "        \n",
    "    def _on_evaluate_step_end(self, inputs, outputs, **kwargs):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # compute loss\n",
    "            logits, loss = self._get_evaluate_loss(inputs, outputs, **kwargs)\n",
    "            self.evaluate_logs['eval_loss'] += loss.item()\n",
    "\n",
    "            labels = inputs['label_ids'].cpu()\n",
    "            logits = logits.cpu()\n",
    "            \n",
    "            batch_size = len(labels)\n",
    "            vocab_size = logits.shape[1]\n",
    "            label_length = labels.shape[1]\n",
    "            \n",
    "            # logits: [batch_size, label_lenght, vocab_size]\n",
    "            logits = logits.reshape([batch_size, -1, vocab_size]).numpy()\n",
    "            \n",
    "            # [label_num, label_length]\n",
    "            labels_ids = np.array(\n",
    "                [self.tokenizer.vocab.convert_tokens_to_ids(\n",
    "                    self.tokenizer.tokenize(_cat)) for _cat in self.cat2id])\n",
    "                                    \n",
    "            preds = np.ones(shape=[batch_size, len(labels_ids)])\n",
    "            \n",
    "            for index in range(label_length):\n",
    "                preds *= logits[:, index, labels_ids[:, index]]\n",
    "                \n",
    "            preds = np.argmax(preds, axis=-1)\n",
    "            \n",
    "            label_indexs = []\n",
    "            for _label in labels.numpy():\n",
    "                _label = \"\".join(\n",
    "                    tokenizer.vocab.convert_ids_to_tokens(list(_label)))\n",
    "                \n",
    "                label_indexs.append(self.cat2id[_label])\n",
    "\n",
    "            label_indexs = np.array(label_indexs)\n",
    "            \n",
    "        self.evaluate_logs['labels'].append(label_indexs)\n",
    "        self.evaluate_logs['logits'].append(preds)\n",
    "\n",
    "        self.evaluate_logs['eval_example'] += len(label_indexs)\n",
    "        self.evaluate_logs['eval_step'] += 1\n",
    "        self.evaluate_logs['eval_acc'] += (label_indexs == preds).sum()\n",
    "\n",
    "    def _on_evaluate_epoch_end(\n",
    "        self,\n",
    "        validation_data,\n",
    "        epoch=1,\n",
    "        is_evaluate_print=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        _labels = np.concatenate(self.evaluate_logs['labels'], axis=0)\n",
    "        _preds = np.concatenate(self.evaluate_logs['logits'], axis=0)\n",
    "\n",
    "        f1_score = sklearn_metrics.f1_score(_labels, _preds, average='macro')\n",
    "\n",
    "        report_ = sklearn_metrics.classification_report(\n",
    "            _labels,\n",
    "            _preds,\n",
    "            target_names=[str(_category) for _category in validation_data.categories]\n",
    "        )\n",
    "\n",
    "        confusion_matrix_ = sklearn_metrics.confusion_matrix(_labels, _preds)\n",
    "\n",
    "        if is_evaluate_print:\n",
    "            print('classification_report: \\n', report_)\n",
    "            print('confusion_matrix_: \\n', confusion_matrix_)\n",
    "            print('test loss is:{:.6f},test acc is:{:.6f},f1_score is:{:.6f}'.format(\n",
    "                self.evaluate_logs['eval_loss'] / self.evaluate_logs['eval_step'],\n",
    "                self.evaluate_logs['eval_acc'] / self.evaluate_logs['eval_example'],\n",
    "                f1_score\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0046f-007d-40c1-93c0-efb8e541a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PromptMLMTask(dl_module, optimizer, 'ce', cuda_device=0, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f7718-8f83-4a0c-a44d-13cba7616b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3108d3-2648-43d8-8378-2e8937aa0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    p_turning_train_dataset,\n",
    "    p_turning_dev_dataset,\n",
    "    lr=2e-5,\n",
    "    epochs=20,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10f553-0bec-45a3-98ce-22e6a9724161",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 四、模型验证与保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9287f8b-c25c-47fb-9eaf-b044db96d68c",
   "metadata": {},
   "source": [
    "#### 1. 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cde6eb-89b4-4b7b-b26b-2d955c86a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ark_nlp.factory.predictor.base._predictor import Predictor\n",
    "\n",
    "\n",
    "class PromptMLMPredictor(Predictor):\n",
    "    \n",
    "    def __init__(self, *args, prompt, **kwargs):\n",
    "        super(PromptMLMPredictor, self).__init__(*args, **kwargs)\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def _convert_to_transfomer_ids(\n",
    "        self,\n",
    "        text\n",
    "    ):\n",
    "        start_mask_position = self.prompt.index(\"[MASK]\")\n",
    "        \n",
    "        mask_position = [\n",
    "            start_mask_position + index\n",
    "            for index in range(len(list(self.cat2id.keys())[0]))\n",
    "        ]\n",
    "        \n",
    "        input_ids = self.tokenizer.sequence_to_ids(text, self.prompt)\n",
    "        input_ids, input_mask, segment_ids = input_ids\n",
    "\n",
    "        features = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': input_mask,\n",
    "            'token_type_ids': segment_ids,\n",
    "            'mask_position': np.array(mask_position)\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def predict_one_sample(\n",
    "        self,\n",
    "        text='',\n",
    "        topk=1,\n",
    "        return_label_name=True,\n",
    "        return_proba=False\n",
    "    ):\n",
    "        if topk is None:\n",
    "            topk = len(self.cat2id) if len(self.cat2id) > 2 else 1\n",
    "\n",
    "        features = self._get_input_ids(text)\n",
    "        self.module.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            inputs = self._get_module_one_sample_inputs(features)\n",
    "            logit = self.module(**inputs).cpu().numpy()\n",
    "                        \n",
    "        # [label_num, label_length]\n",
    "        labels_ids = np.array(\n",
    "            [self.tokenizer.vocab.convert_tokens_to_ids(\n",
    "                self.tokenizer.tokenize(_cat)) for _cat in self.cat2id])\n",
    "\n",
    "        preds = np.ones(shape=[len(labels_ids)])\n",
    "        \n",
    "        label_length = len(list(self.cat2id.keys())[0])\n",
    "\n",
    "        for index in range(label_length):\n",
    "            preds *= logit[index, labels_ids[:, index]]\n",
    "            \n",
    "        preds = torch.Tensor(preds)\n",
    "        preds = preds.reshape(1, -1)\n",
    "\n",
    "        probs, indices = preds.topk(topk, dim=1, sorted=True)\n",
    "\n",
    "        preds = []\n",
    "        probas = []\n",
    "        for pred_, proba_ in zip(indices.cpu().numpy()[0], probs.cpu().numpy()[0].tolist()):\n",
    "\n",
    "            if return_label_name:\n",
    "                pred_ = self.id2cat[pred_]\n",
    "\n",
    "            preds.append(pred_)\n",
    "\n",
    "            if return_proba:\n",
    "                probas.append(proba_)\n",
    "\n",
    "        if return_proba:\n",
    "            return list(zip(preds, probas))\n",
    "\n",
    "        return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22def42a-ffec-4907-b358-51a65b11d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_turning_instance = PromptMLMPredictor(model.module, tokenizer, p_turning_train_dataset.cat2id, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3162e-3117-4b31-ab99-08f86871fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_turning_instance.predict_one_sample('小米就要港股上市了，那么为什么选择香港而没有选择上海？', topk=15, return_proba=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
